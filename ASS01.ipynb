{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnDn32wueGYcfp/RtTk/rW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A51174/GENERATIVE-AI-BATCH-39-/blob/main/ASS01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6nfqallQ-Ne",
        "outputId": "bd3d1e33-2c8e-4d71-caee-1ba9d3227fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n",
            "R-squared: 0.99877\n",
            "\n",
            "Library Results:\n",
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n",
            "R-squared: 0.99877\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "y_actual = np.array([20, 30, 40, 50, 60])\n",
        "y_pred = np.array([20.5, 30.3, 40.2, 50.6, 60.7])\n",
        "def mae(y_actual, y_pred):\n",
        "    return np.mean(np.abs(y_actual - y_pred))\n",
        "def mse(y_actual, y_pred):\n",
        "    return np.mean((y_actual - y_pred) ** 2)\n",
        "def rmse(y_actual, y_pred):\n",
        "    return np.sqrt(mse(y_actual, y_pred))\n",
        "def r2_score(y_actual, y_pred):\n",
        "    y_mean = np.mean(y_actual)\n",
        "    ss_total = np.sum((y_actual - y_mean) ** 2)\n",
        "    ss_residual = np.sum((y_actual - y_pred) ** 2)\n",
        "    return 1 - (ss_residual / ss_total)\n",
        "mae_value = mae(y_actual, y_pred)\n",
        "mse_value = mse(y_actual, y_pred)\n",
        "rmse_value = rmse(y_actual, y_pred)\n",
        "r2_value = r2_score(y_actual, y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae_value)\n",
        "print(\"Mean Squared Error (MSE):\", mse_value)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse_value)\n",
        "print(\"R-squared:\", r2_value)\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score as r2_sklearn\n",
        "mae_sklearn = mean_absolute_error(y_actual, y_pred)\n",
        "mse_sklearn = mean_squared_error(y_actual, y_pred)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "r2_sklearn_value = r2_sklearn(y_actual, y_pred)\n",
        "print(\"\\nLibrary Results:\")\n",
        "print(\"Mean Absolute Error (MAE):\", mae_sklearn)\n",
        "print(\"Mean Squared Error (MSE):\", mse_sklearn)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse_sklearn)\n",
        "print(\"R-squared:\", r2_sklearn_value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "y_actual = np.array([0, 0, 0, 0, 0, 0, 0])\n",
        "y_pred = np.array([1, 1, 0, 2, 1, 0, 2])\n",
        "accuracy = accuracy_score(y_actual, y_pred)\n",
        "precision = precision_score(y_actual, y_pred, average='weighted')\n",
        "recall = recall_score(y_actual, y_pred, average='weighted')\n",
        "f1 = f1_score(y_actual, y_pred, average='weighted')\n",
        "cm = confusion_matrix(y_actual, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvzA9tpQRIuh",
        "outputId": "f18b1d07-9b1e-4b33-d3c2-0e7569d244b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2857142857142857\n",
            "Precision: 1.0\n",
            "Recall: 0.2857142857142857\n",
            "F1-score: 0.44444444444444436\n",
            "Confusion Matrix:\n",
            " [[2 3 2]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}